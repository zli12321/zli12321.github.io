---
title:          "First Frame Is the Place to Go for Video Content Customization"
date:           2025-11-20 20:01:00 +0800
selected:       true
pub:            "Preprint"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"
# semantic_scholar_id: 204e3073870fae3d05bcbc2f6a8e263d9b72e776  # use this to retrieve citation count
abstract: >-
  What role does the first frame play in video generation models? Traditionally, it's viewed as the spatial-temporal starting point of a video, merely a seed for subsequent animation. In this work, we reveal a fundamentally different perspective: video models implicitly treat the first frame as a conceptual memory buffer that stores visual entities for later reuse during generation. Leveraging this insight, we show that it's possible to achieve robust and generalized video content customization in diverse scenarios, using only 20-50 training examples without architectural changes or large-scale finetuning. This unveils a powerful, overlooked capability of video generation models for reference-based video customization.

cover:          /assets/images/covers/ffgo.png
authors:
  - Jingxi Chen*
  - Zongxia Li*
  - Zhichao Liu*
  - Guangyao Shi
  - Xiyang Wu
  - Fuxiao Liu
  - Cornelia Ferm√ºller
  - Brandon Y. Feng
  - Yiannis Aloimonos


links:
  Website: https://firstframego.github.io/
  Unofficial Youtube Showcase: https://www.youtube.com/watch?v=Dks3q5w7sdw
  Paper: https://arxiv.org/pdf/2511.15700
---
